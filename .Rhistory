obs <- testStat(BCcounts,group)
obs
mean(Bdata$count)-mean(Cdata$count)
sample(group)
"perms <- sapply(1 : 10000, function(i) testStat(BCcounts, sample(group)))"
mean(perms>obs)
testStat(DEcounts,group)
skip()
perms > obs
mean(perms>obs)
testStat(DEcounts,group)
"perms <- sapply(1 : 10000, function(i) testStat(DEcounts, sample(group)))"
perms <- sapply(1 : 10000, function(i) testStat(DEcounts, sample(group)))
install.packages('knitr', dependencies = TRUE)
xbar <- 1100
sd <- 30
xbar + c(-1, 1) * qt(0.975, n-1) * (sd / sqrt(n))
xbar <- -2
n <- 9
xbar * sqrt(n) / qt(0.975, n-1)
# plot likelihood
## Statistical Inference Course Project
## Inferential data analysis
## Author: Chakra c
## Overview:
# Investigate the exponential distribution in R and compare it with the Central Limit Theorem.
# Note that the data arises from a family of distributions indexed by a parameter which
# represents a useful summary of the data.
# Definition: Given a statistical probability of mass function/density, f(x, theta)
# where theta is an unknown parameter, f as function of theta for a fixed, observed value of x.
# plot possibilities
pvals <- seq(0, 1, length = 1000)
plot(pvals, dbinom(3, 4, pvals) / dbinom(3, 4, 3/4), type = "l", frame = F,
lwd = 3, xlab = "p", ylab = "possibilities / max possibilities")
lambda <- seq(0, .2, length = 1000)
possibilities <- dpois(5, 94 * lambda) / dpois(5, 5)
plot(lambda, possibilities, frame = F, lwd = 3, type = "l", xlab = expression(lambda))
lines(rep(5/94, 2), 0 : 1, col = "red", lwd = 3)
lines(range(lambda[possibilities > 1 / 16]), rep(1 / 16, 2), lwd = 2)
lines(range(lambda[possibilities > 1 / 8]), rep(1 / 8, 2), lwd = 2)
## Inference
# Exploring the density
library(manipulate)
pvals <- seq(0.01, 0.99, length = 1000)
manipulate(
plot(pvals, dbeta(pvals, alpha, beta), type = "l", lwd = 3, frame = F),
alpha = slider(0.01, 10, initial = 1, step = .5),
beta = slider(0.01, 10, initial = 1, step = .5)
)
##
pvals <- seq(0.01, 0.99, length = 1000)
x <- 13
n <- 20
myPlot <- function(alpha, beta) {
plot(0 : 1, 0 : 1, type = "n", xlab = "p", ylab = "", frame = F)
lines(pvals, dbeta(pvals, alpha, beta) / max(dbeta(pvals, alpha, beta)),
lwd = 3, col = "darkred")
lines(pvals, dbinom(x, n, pvals) / dbinom(x, n, x/n),
lwd = 3, col = "darkblue")
lines(pvals, dbeta(pvals, alpha+x, beta+(n-x))/max(dbeta(pvals, alpha+x, beta+(n-x))),
lwd = 3, col = "darkgreen")
title("red = prior, green = posterior, blue = possibilities")
}
manipulate(
myPlot(alpha, beta),
alpha = slider(0.01, 100, initial = 1, step = .5),
beta = slider(0.01, 100, initial = 1, step = .5)
)
## Confidence intervals
library(binom)
binom.bayes(13, 20, type = "highest")
pvals <- seq(0.01, 0.99, length = 1000)
x <- 13
n <- 20
myPlot2 <- function(alpha, beta, cl) {
plot(pvals, dbeta(pvals, alpha+x, beta+(n-x)), type = "l",
lwd = 3, xlab = "p", ylab = "", frame = F)
out <- binom.bayes(x, n, type = "highest",
prior.shape1 = alpha,
prior.shape2 = beta,
conf.level = cl)
p1 <- out$lower
p2 <- out$upper
lines(c(p1, p1, p2, p2), c(0, dbeta(c(p1, p2), alpha+x, beta+(n-x)), 0),
type = "l", lwd = 3, col = "darkred")
}
manipulate(
myPlot2(alpha, beta, cl),
alpha = slider(0.01, 10, initial = 1, step = .5),
beta = slider(0.01, 10, initial = 1, step = .5),
cl = slider(0.01, 0.99, initial = 0.95, step = .01)
)
## 2 Group Intervals
# x_oc = 132.86, s_oc = 15.34; x_c = 127.44, s_c = 18.23
sp <- sqrt((7*15.34^2 + 20*18.23^2) / (8 + 21 - 2))
132.86 - 127.44 + c(-1, 1)*qt(.975, 27) * sp * (1 / 8 + 1 / 21)^.5
data(sleep)
x1 <- sleep$extra[sleep$group == 1]
x2 <- sleep$extra[sleep$group == 2]
n1 <- length(x1)
n2 <- length(x2)
sp <- sqrt( ((n1 - 1) * sd(x1)^2 + (n2 - 1) * sd(x2)^2) / (n1 + n2 - 2))
md <- mean(x1) - mean(x2)
semd <- sp * sqrt(1 / n1 + 1 / n2)
md + c(-1, 1) * qt(.975, n1 + n2 - 2) * semd
t.test(x1, x2, paired = F, var.equal = T)$conf
# t.test(x1, x2, paired = F, var.equal = F)$conf
## Confidence Intervals testing
# Usage: Construct decisions based on data
# T test in R
library(UsingR)
data(father.son)
t.test(father.son$sheight - father.son$fheight)
The exponential distribution can be simulated in R with `rexp(n, lambda)` where
`lambda` $\lambda$ is the rate parameter. The mean of exponential distribution is
$1/\lambda$ and the standard deviation is also $1/\lambda$. For this simulation,
we set $\lambda=0.2$. In this simulation, we investigate the distribution of
averages of 40 numbers sampled from exponential distribution with $\lambda=0.2$.
Let's do a thousand simulated averages of 40 exponentials.
```{r}
set.seed(3)
lambda <- 0.2
num_sim <- 1000
sample_size <- 40
sim <- matrix(rexp(num_sim*sample_size, rate=lambda), num_sim, sample_size)
row_means <- rowMeans(sim)
```
The distribution of sample means is as follows.
```{r echo=FALSE}
# plot the histogram of averages
hist(row_means, breaks=50, prob=TRUE,
main="Distribution of averages of samples,
drawn from exponential distribution with lambda=0.2",
xlab="")
# density of the averages of samples
lines(density(row_means))
# theoretical center of distribution
abline(v=1/lambda, col="red")
# theoretical density of the averages of samples
xfit <- seq(min(row_means), max(row_means), length=100)
yfit <- dnorm(xfit, mean=1/lambda, sd=(1/lambda/sqrt(sample_size)))
lines(xfit, yfit, pch=22, col="red", lty=2)
# add legend
legend('topright', c("simulation", "theoretical"), lty=c(1,2), col=c("black", "red"))
```
The distribution of sample means is centered at `r mean(row_means)`
and the theoretical center of the distribution is $\lambda^{-1}$ = `r 1/lambda`.
The variance of sample means is `r var(row_means)` where the theoretical variance
of the distribution is $\sigma^2 / n = 1/(\lambda^2 n) = 1/(0.04 \times 40)$ =
`r 1/(0.04 * 40)`.
Due to the central limit theorem, the averages of samples follow normal
distribution. The figure above also shows the density computed using the histogram and the
normal density plotted with theoretical mean and variance values. Also, the
q-q plot below suggests the normality.
```{r echo=FALSE}
qqnorm(row_means); qqline(row_means)
```
Finally, let's evaluate the coverage of the confidence interval for
$1/\lambda = \bar{X} \pm 1.96 \frac{S}{\sqrt{n}}$
```{r echo=FALSE}
lambda_vals <- seq(4, 6, by=0.01)
coverage <- sapply(lambda_vals, function(lamb) {
mu_hats <- rowMeans(matrix(rexp(sample_size*num_sim, rate=0.2),
num_sim, sample_size))
ll <- mu_hats - qnorm(0.975) * sqrt(1/lambda**2/sample_size)
ul <- mu_hats + qnorm(0.975) * sqrt(1/lambda**2/sample_size)
mean(ll < lamb & ul > lamb)
})
library(ggplot2)
qplot(lambda_vals, coverage) + geom_hline(yintercept=0.95)
```
The 95% confidence intervals for the rate parameter ($\lambda$) to be estimated
($\hat{\lambda}$) are
$\hat{\lambda}_{low} = \hat{\lambda}(1 - \frac{1.96}{\sqrt{n}})$ agnd
$\hat{\lambda}_{upp} = \hat{\lambda}(1 + \frac{1.96}{\sqrt{n}})$.
As can be seen from the plot above, for selection of $\hat{\lambda}$ around 5,
the average of the sample mean falls within the confidence interval at least 95% of the time.
Note that the true rate, $\lambda$ is 5.
The report including the code for plots is available at
http://github.com/sefakilic/coursera-statinference/blob/master/statinference_project_part1_full.md
geom_bar(stat="Identity",) +
## ------------------------------------------------------------------------
library(datasets)
library(ggplot2)
ggplot(data=ToothGrowth, aes(x=as.factor(dose), y=len, fill=supp)) +
geom_bar(stat="Identity",) +
facet_grid(. ~ supp) +
xlab("Dose shown miligrams") +
ylab("Tooth growth length") +
guides(fill=guide_legend(title="Supp Type"))
## ------------------------------------------------------------------------
fit <- lm(len ~ dose + supp, data=ToothGrowth)
summary(fit)
## ------------------------------------------------------------------------
confint(fit)
x <- c(0.18, -1.54, 0.42, 0.95)
w <- c(2, 1, 3, 1)
optimize(function(u){ sum(w*(x-u)^2)}, interval=c(-100,100))
x <- c(0.8, 0.47, 0.51, 0.73, 0.36, 0.58, 0.57, 0.85, 0.44, 0.42)
y <- c(1.39, 0.72, 1.55, 0.48, 1.19, -1.59, 1.23, -0.65, 1.49, 0.05)
fit <- lm(y ~ x -1)
coefficients(fit)
data(mtcars)
dB <- as.data.frame(mtcars)
fit <- lm(mpg ~ weight, data = dB)
fit <- lm(mpg ~ wt, data = dB)
coefficients(fit)
corOfYandX <- 0.5
sdYoverX <- 2
beta1 <- corOfYandX*sdYoverX
beta1
1.5*.4
x <- c(8.58, 10.46, 9.01, 9.64, 8.86)
xn <- (x - mean(x))/sd(x)
xn
x <- c(0.8, 0.47, 0.51, 0.73, 0.36, 0.58, 0.57, 0.85, 0.44, 0.42)
y <- c(1.39, 0.72, 1.55, 0.48, 1.19, -1.59, 1.23, -0.65, 1.49, 0.05)
fit <- lm(y ~ x)
coefficients(fit)
install.packages("swirl")
install.packages("swirl")
install.packages("swirl")
install.packages("swirl")
install.packages("swirl")
install.packages("swirl")
library(swirl)
swirl()
plot(child ~ parent, galton)
plot(cjitter(child,4) ~ parent,galton)
plot(jitter(child,4) ~ parent,galton)
regrline <- lm(child ~ parent, galton)
abline(regrline, lwd=3,
| col='red')
abline(regrline, lwd=3,| col='red')
abline(regrline, lwd=3, col='red')
summary(regrline)
child ~ parent
fit <- lm(child ~ parent, galton)
summary(fit)
fit$residuals
mean(fit$residuals)
cov(fit$residuals, galton$parent)
fit$coef[1]
ols.ic <- fit$coef[1]
ols.slope <- fit$coef[2]
lhs-rhs
all.equal(lhs,rhs)
varChild <- var(galton$child)
varRes <- var(fit$residuals)
varEst <- var(est(ols.slope, ols.ic))
all.equal(varChild,varEst+varRes)
efit <- lm(accel ~ mag+dist, attenu)
mean(efit$residuals)
cov(efit$residuals, attenu$mag)
ANY_of_exprs('cov(efit$residuals, attenu$dist)','cov(attenu$dist,efit$residuals)')
cov(efit$residuals, attenu$dist)
cor(gpa_nor,gch_nor)
l_nor <- lm(gch_nor ~ gpa_nor)
fit <- lm(child ~ parent, galton)
sqrt(sum(fit$residuals^2) / (n - 2))
summary(fit)$sigma
sqrt(deviance(fit)/(n-2))
mu <- mean(galton$child)
sTot <- sum((galton$child-mu)^2)
sRes <- deviance(fit)
1-sRes/sTot
summary(fit)$r.squared
cor(galton$parent,galton$child)^2
ones <- rep(1, nrow(galton))
lm(child ~ ones + parent - 1, galton)
lm(child ~ parent, galton)
lm(child ~ 1, galton)
head(trees)
fit <- lm(Volume ~ . - 1, trees)
'trees2 <- eliminate("Girth", trees)'
head(trees2)
trees2 <- eliminate("Girth", trees)
head(trees2)
fit2 <- lm(Volume ~ . - 1, trees2)
lapply(list(fit, fit2), coef)
all <- lm(Fertility ~ ., swiss)
summary(all)
summary(lm(Fertility ~ Agriculture, swiss))
cor(swiss$Examination,swiss$Education)
cor(swiss$Agriculture,swiss$Education)
makelms()
ec <- swiss$Examination+swiss$Catholic
efit <- lm(Fertility ~ . + ec, swiss)
all$coefficients - efit$coefficients
install.packages("swirl")
install.packages("swirl")
install.packages("swirl")
library(swirl)
swirl()
6
dim(InsectSprays)
head(InsectSprays,15)
sA
summary(InsectSprays[,2])
sapply(InsectSprays,class)
fit <- lm(count ~ spray, InsectSprays)
summary(fit)$coef
est <- summary(fit)$coef[,1]
mean(sA)
mean(sB)
nfit <- lm(count ~ spray - 1, InsectSprays)
summary(nfit)$coef
spray2 <- relevel(InsectSprays$spray,"C")
fit2 <- lm(count ~ spray2, InsectSprays)
summary(fit2)$coef
mean(sC)
(fit$coef[2]-fit$coef[3])/1.6011
dim(hunger)
948
names(hunger)
fit <- lm(hunger$Numeric ~ hunger$Year)
summary(fit)$coef
lmF <- lm(hunger$Numeric[hunger$Sex=="Female"] ~ hunger$Year[hunger$Sex=="Female"])
lmM <- lm(hunger$Numeric[hunger$Sex=="Male"] ~ hunger$Year[hunger$Sex=="Male"])
lmBoth <- lm(hunger$Numeric ~ hunger$Year + hunger$Sex)
summary(lmBoth)
lmInter <- lm(hunger$Numeric ~ hunger$Year + hunger$Sex + hunger$Year * hunger$Sex)
summary(lmInter)
fit <- lm(y ~ x, out2)
plot(fit, which=1)
fitno <- lm(y ~ x, out2[-1, ])
plot(fitno, which=1)
coef(fit)-coef(fitno)
head(dfbeta(fit))
resno <- out2[1, "y"] - predict(fitno, out2[1,])
1-resid(fit)[1]/resno
head(hatvalues(fit))
sigma <- sqrt(deviance(fit)/df.residual(fit))
rstd <- resid(fit)/(sigma * sqrt(1-hatvalues(fit)))
head(cbind(rstd, rstandard(fit)))
plot(fit, which=3)
plot(fit, which=2)
sigma1 <- sqrt(deviance(fitno)/df.residual(fitno))
resid(fit)[1]/(sigma1*sqrt(1-hatvalues(fit)[1]))
head(rstudent(fit))
dy <- predict(fitno, out2)-predict(fit, out2)
sum(dy^2)/(2*sigma^2)
plot(fit, which=5)
rgp1()
rgp2()
head(swiss)
mdl <- lm(Fertility ~ ., swiss)
vif(mdl)
mdl2 <- lm(Fertility ~ . -Examination, swiss)
vif(mdl2)
x1c <- simbias()
apply(x1c, 1, mean)
fit1 <- lm(Fertiliy ~ Agriculture, swiss)
apply(x1c, 1, mean)
fit1 <- lm(Fertility ~ Agriculture, swiss)
fit3 <- lm(Fertility ~ Agriculture + Examination + Education, swiss)
anova(fit1, fit3)
deviance(fit3)
d <- deviance(fit3)/43
n <- (deviance(fit1) - deviance(fit3))/2
n/d
pf(n/d, 2, 43, lower.tail=FALSE)
shapiro.test(fit3$residuals)
anova(fit1, fit3, fit5, fit6)
install.packages("swirl")
install.packages("swirl")
library(swirl)
swirl()
ravenData
mdl <- glm(ravenWinNum ~ ravenScore, binomial, ravenData)
lodds <- predict(mdl, data.frame(ravenScore=c(0, 3, 6)))
exp(lodds)/(1+exp(lodds))
summary(mdl)
exp(confint(mdl))
anova(mdl)
qchisq(0.95, 1)
var(rpois(1000, 50))
View(hits)
class(hits[,'date'])
class(hits[,'date'])
mdl <- glm(visits ~ date, poisson, hits)
summary(mdl)
exp(confint(mdl, 'date'))
which.max(hits[,'visits'])
hits[704,]
lambda <- mdl$fitted.values[704]
qpois(.95, lambda)
mdl2 <- glm(simplystats ~ date, poisson, hits, offset=log(visits+1))
qpois(.95, mdl2$fitted.values[704])
lambda
The log of the mean
lambda
class(hits[,'date'])
install.packages("swirl")
install.packages("swirl")
library(swirl)
swirl()
var(rpois(1000, 50))
View(hits)
class(hits[,'date'])
class(hits[,'date'])
as.integer(head(hits[,'date'])
;
as.integer(head(hits[,'date'])
;
info()
skip()
class(hits[,'date'])
class(hits[,'date'])
ANY_of_exprs("as.integer(head(hits[,'date']))", 'as.integer(head(hits[,"date"]))', 'as.integer(head(hits[,1]))', 'as.integer(head(hits$date))')
skip()
as.integer(head(hits[,'date']), or something equivalent
x <- as.integer(head(hits[,'date'])
;
skip()
skip()
class(hits[,'date'])
class(hits[,'date'])
class(hits[,'date'])
mdl <- glm(visits ~ date, poisson, hits)
info()
skip()
integer(head(hits[,'date'])
integer(head(hits[,'date'])
ANY_of_exprs("as.integer(head(hits[,'date']))", 'as.integer(head(hits[,"date"]))', 'as.integer(head(hits[,1]))', 'as.integer(head(hits$date))')
as.integer(head(hits[,'date']))", 'as.integer(head(hits[,"date"]))', 'as.integer(head(hits[,1]))', 'as.integer(head(hits$date))'
(as.integer(head(hits[,'date'])), 'as.integer(head(hits[,"date"]))', 'as.integer(head(hits[,1]))', 'as.integer(head(hits$date))
skip()
info()
skip()
skip()
skip()
skip()
class(hits[,'date'])
class(hits[,'date'])
class(hits[,'date'])
class(hits[,'date'])
exit;
close
info()
main()
install.packages("swirl")
install.packages("swirl")
library(swirl)
swirl()
var(rpois(1000, 50))
nxt()
View(hits)
class(hits[,'2012-01-30'])
class(hits[,'date'])
class(hits[,'date'])
as.integer(head(hits[,'date'])
;
as.integer(head(hits[,'date'])
;
as.integer(head(hits[,'date']))
install.packages("swirl")
install.packages("swirl")
library(swirl)
swirl()
var(rpois(1000, 50))
nxt()
View(hits)
class(hits[,'date'])
as.integer(head(hits[,'date']))
mdl <- glm(visits ~ date, poisson, hits)
summary(mdl)
exp(confint(mdl, 'date'))
which.max(hits[,'visits'])
hits[704,]
lambda <- mdl$fitted.values[704]
qpois(.95, lambda)
mdl2 <- glm(simplystats ~ date, poisson, hits, offset=log(visits+1))
qpois(.95, mdl2$fitted.values[704])
library(ggplot2)
data(mtcars)
mtcars[1:3, ] # Sample Data
dim(mtcars)
mtcars$cyl <- as.factor(mtcars$cyl)
mtcars$vs <- as.factor(mtcars$vs)
mtcars$am <- factor(mtcars$am)
mtcars$gear <- factor(mtcars$gear)
mtcars$carb <- factor(mtcars$carb)
attach(mtcars)
library(ggplot2)
data(mtcars)
mtcars[1:3, ] # Sample Data
dim(mtcars)
mtcars$cyl <- as.factor(mtcars$cyl)
mtcars$vs <- as.factor(mtcars$vs)
mtcars$am <- factor(mtcars$am)
mtcars$gear <- factor(mtcars$gear)
mtcars$carb <- factor(mtcars$carb)
attach(mtcars)
data(mtcars)
attach(mtcars)
fit <- lm(mpg ~ as.factor(cyl) + wt, data=mtcars)
summary(fit) # as.factor(cyl)8  -6.0709
library(caret)
library(caret)
install.packages(c("caret:", "v6.0.47"))
install.packages("C:/Coursera/Data_Science/Practical_Machine_Learning/caret_6.0-47.zip", repos = NULL)
install.packages("C:/Users/cchippala/Downloads/caret_6.0-47.tar.gz", repos = NULL, type = "source")
install.packages("C:/Users/cchippala/Downloads/caret_6.0-47.zip", repos = NULL)
library(caret)
install.packages("C:/Users/cchippala/Downloads/rpart_4.1-9.zip", repos = NULL)
install.packages("C:/Users/cchippala/Downloads/pgmm_1.2.zip", repos = NULL)
install.packages("C:/Users/cchippala/Downloads/ElemStatLearn_2012.04-0.zip", repos = NULL)
install.packages("C:/Users/cchippala/Downloads/AppliedPredictiveModeling_1.1-6.zip", repos = NULL)
install.packages("C:/Users/cchippala/Downloads/caret_6.0-47.zip", repos = NULL)
setwd("C:/Coursera/Data_Science/Practical_Machine_Learning")
install.packages("C:/Users/cchippala/Downloads/RANN_2.5.zip", repos = NULL)
